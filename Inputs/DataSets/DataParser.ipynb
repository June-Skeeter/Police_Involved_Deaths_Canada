{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook incorporate the Killercopscanada data + a data from news artcles found from google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dateparser\n",
    "import datefinder\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import difflib\n",
    "import string\n",
    "from IPython.display import clear_output\n",
    "from dateparser.search import search_dates\n",
    "from dateparser_data.settings import default_parsers\n",
    "parsers = [parser for parser in default_parsers if parser != 'relative-time']\n",
    "# >>> parse('today', settings={'PARSERS': parsers})\n",
    "\n",
    "can_province_names = {\n",
    "      'Alberta':'AB',\n",
    "      'British Columbia':'BC',\n",
    "      'Manitoba':'MB',\n",
    "      'New Brunswick':'NB',\n",
    "      'Newfoundland and Labrador':'NL',\n",
    "      'Newfoundland':'NL',\n",
    "      'Nova Scotia':'NS',\n",
    "      'Northwest Territories':'NT',\n",
    "      'Nunavut':'NU',\n",
    "      'Ontario':'ON',\n",
    "      'Prince Edward Island':'PE',\n",
    "      'Quebec':'QC',\n",
    "      'Saskatchewan':'SK',\n",
    "      'Yukon':'YT',\n",
    "    }\n",
    "\n",
    "\n",
    "can_province_keys = {\n",
    "      'AB':'Alberta',\n",
    "      'BC':'British Columbia',\n",
    "      'MB':'Manitoba',\n",
    "      'NB':'New Brunswick',\n",
    "      'NL':'Newfoundland and Labrador',\n",
    "      'NS':'Nova Scotia',\n",
    "      'NT':'Northwest Territories',\n",
    "      'NU':'Nunavut',\n",
    "      'ON':'Ontario',\n",
    "      'PE':'Prince Edward Island',\n",
    "      'QC':'Quebec',\n",
    "      'SK':'Saskatchewan',\n",
    "      'YT':'Yukon',\n",
    "    }\n",
    "\n",
    "\n",
    "def Assign_Death_Code(df,Keys,Cols,Type,Recat=999,Validate = False,ValCols=None):\n",
    "    for k in Keys:\n",
    "        for c in Cols:\n",
    "            if Validate == True:\n",
    "                print(df.loc[((df['Death_Category']==Recat)&\n",
    "                    (df[c].str.contains(k, flags=re.IGNORECASE, regex=True))),\n",
    "                   ValCols].values)\n",
    "            else:\n",
    "                df.loc[((df['Death_Category']==Recat)&\n",
    "                    (df[c].str.contains(k, flags=re.IGNORECASE, regex=True))),\n",
    "                   'Death_Category']=Death_Catageory_Code[Type]\n",
    "            \n",
    "def FindDates(ss):\n",
    "    flag = 'Parsed'\n",
    "    \n",
    "    DD = re.findall (r'\\((.*?)\\)',ss)\n",
    "    for d in DD:\n",
    "        if len(d)<=4:\n",
    "            ss=ss.replace('('+d+')','')\n",
    "    DD = re.findall(r'(?<=-)\\w+',ss)\n",
    "    for d in DD:\n",
    "        ss = ss.replace('-'+d,'')\n",
    "    DD = re.findall(r'(?<=/)\\w+',ss)\n",
    "    if len(DD)==1:\n",
    "        ss = ss.replace('/'+DD[0],'')\n",
    "    s = ss.replace('(',' _ ').replace(')',' _ ').replace('.','').replace(',','').replace('$1500','')\n",
    "    Result=search_dates(s,languages=['en'], settings={'PARSERS': parsers,\n",
    "                                                           'PREFER_DAY_OF_MONTH': 'first',\n",
    "#                                                            'PREFER_DATES_FROM': 'past',\n",
    "#                                                            'REQUIRE_PARTS': ['month', 'year']\n",
    "                                                          })\n",
    "    if Result is not None:\n",
    "        date = Result[-1][-1]\n",
    "    else:\n",
    "        date = None\n",
    "        \n",
    "    return(date,flag)\n",
    "            \n",
    "Death_Catageory_Code = {\n",
    "    'Shooting':1,\n",
    "#     'Rubber Bullet':2,\n",
    "    'Taser':3,\n",
    "    'Other Weapon':4,\n",
    "    'Excited Delirium':9,\n",
    "    'Use of Force':10,\n",
    "    'Accidental':15,\n",
    "    'Overdose/Intoxication':25,\n",
    "    'Vehicle':50,\n",
    "    'In Custody':75,\n",
    "    'Suicide':100,\n",
    "    'Other/Unknown':999\n",
    "}\n",
    "Death_Category_SearchKeys = {\n",
    "    'Shooting':['shoot','shot ','gunshot','rubber bullet','fired'],\n",
    "#     'Rubber Bullet':[],\n",
    "    'Taser':['tase','taze','stun gun'],\n",
    "    'Other Weapon':['baton','club','pepper spray','pepper-spray'],\n",
    "    'Excited Delirium':['excited delirium'],    \n",
    "    'Use of Force':['Physical force','restrain','subdue','struggling','struggled','resisted','altercation',\n",
    "                    'broken rib','collapsed lung',\"beat and kick\",'dragged','held him down'\n",
    "#                     'handcuff','apprehended',\n",
    "#                     'arrested','Anoxic brain injury','interact','trauma','bleeding','blood','strangling',\n",
    "#                     'head injury','collapsed lung','pushed','fight','resisting','kicked','altercation',\n",
    "#                     'respiratory failure','injuries'\n",
    "                   ],\n",
    "    'Accidental':['Fall','Fell','jump','hypothermia','drowning','suffocat'],\n",
    "    'Overdose/Intoxication':['Methamphetamine','Cocaine','methadone','alcohol','pills','drugs',\n",
    "                 'intoxication','overdose','toxicity','blocked with vomit'],\n",
    "    'Vehicle':['crash','vehicle',\"hit by officer's car\",'collision'],\n",
    "    'In Custody':['cell','custody','hospital','Died of an allergy','Found unresponsive','Segregation'],\n",
    "    'Suicide':['suicide','suicidal','hang','hung','self-inflicted','Incisions of neck'],\n",
    "    'Other/Unknown':['Unknown']\n",
    "}\n",
    "\n",
    "# Month_Abb{}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Killer Cops Canada Data\n",
    "* I've scraped this wordpress blog and saved the data (see other notebook) and saved the data as .json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Length = []\n",
    "Date = []\n",
    "TitleDate = []\n",
    "TitleDate_Flag = []\n",
    "Title = []\n",
    "Summary = []\n",
    "ID = []\n",
    "# Keys = []\n",
    "Prov = []\n",
    "URL = []\n",
    "Categories = []\n",
    "for i in range (1,31):\n",
    "    filename = \"killercopscanada/page\"+str(i)+\".json\"\n",
    "\n",
    "    with open(filename) as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "        for post in json_data['posts']: \n",
    "#             if post['ID']== 1535:#_KCC\n",
    "            Date.append(post['date'])\n",
    "            Length.append(len(post['content']))\n",
    "            Title.append(post['title'])\n",
    "            Summary.append(post['content'])\n",
    "            ID.append(str(post['ID'])+'_KCC')\n",
    "#             Keys.append(list(post['tags'].keys()))\n",
    "            Tag_Cat = list(post['categories'].keys())+list(post['tags'].keys())\n",
    "            Categories.append(list(dict.fromkeys(Tag_Cat))) ## Remove duplicates\n",
    "#             matches = datefinder.find_dates(post['title'].replace('Sept.','Sep.'))\n",
    "            URL.append(post['URL'])\n",
    "#             print(post['title'])\n",
    "            date,flag = FindDates(post['title'])\n",
    "            TitleDate.append(date)\n",
    "            TitleDate_Flag.append(flag)\n",
    "\n",
    "KCC = pd.DataFrame(data = {'ID':ID,\n",
    "                           'URL':URL,\n",
    "                           'PostDate':Date,\n",
    "                           'Title':Title,\n",
    "                           'Categories':Categories,\n",
    "#                            'Tags':Keys,\n",
    "                           'PostLength':Length,\n",
    "                           'Text':Summary,\n",
    "                           'TitleDate':TitleDate,\n",
    "                           'TitleDate_Flag':TitleDate_Flag})\n",
    "\n",
    "KCC = KCC.set_index(pd.DatetimeIndex(KCC['PostDate']))\n",
    "KCC['Match']=0\n",
    "KCC.index=KCC.index.tz_localize(None)\n",
    "# [1,1,1,1]\n",
    "# KCC.loc[((KCC.index-KCC['TitleDate']<datetime.timedelta(-1))&(KCC['TitleDate_Flag']=='Found')),'TitleDate']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss = 'July 7-8, 2020'\n",
    "#     print(d)\n",
    "#     if len(d)<=4:\n",
    "#         ss=ss.replace('('+d+')',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prov\n",
      "AB              89\n",
      "BC              99\n",
      "MB              42\n",
      "Multiple         7\n",
      "NB              13\n",
      "NL               5\n",
      "NS               8\n",
      "NU               9\n",
      "ON             193\n",
      "PE               1\n",
      "QC              96\n",
      "SK              21\n",
      "Unspecified      4\n",
      "YT               2\n",
      "Name: ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print(KCC.loc[KCC['TitleDate_Flag']=='Missing'][-1:].values)\n",
    "# print(KCC['Tags'])\n",
    "KCC['prov']='Unspecified'\n",
    "\n",
    "for i,row in KCC.iterrows():\n",
    "    pc = 0\n",
    "    for cat in row['Categories']:\n",
    "        try:\n",
    "            KCC.loc[KCC.index==i,'prov']=can_province_names[cat]\n",
    "            pc += 1\n",
    "        except:\n",
    "            pass\n",
    "    if pc > 1:\n",
    "        KCC.loc[KCC.index==i,'prov']='Multiple'\n",
    "# print(KCC['Categories'])\n",
    "print(KCC.groupby('prov').count()['ID'])\n",
    "# T = KCC.loc[KCC['ID']=='1039_KCC']\n",
    "# print(T.index-T.TitleDate,T.TitleDate)\n",
    "# print(KCC.loc[((KCC.index-KCC['TitleDate']<datetime.timedelta(-1))&(KCC['TitleDate_Flag']=='Found')),'TitleDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(589, 11)\n",
      "C.R.A.P\n",
      "(562, 11)\n",
      "Police-Involved Deaths in Canada in 2017:\n",
      "(561, 11)\n",
      "People who Died Following a Police Intervention Since 1987\n",
      "(560, 11)\n",
      "Activists Killed by Cops\n",
      "(552, 11)\n",
      "A Victim of Power\n",
      "(552, 11)\n",
      "Third Consecutive Yearly Increase in Police-Involved Deaths in BC\n",
      "(551, 11)\n",
      "Deadly Force\n",
      "(550, 11)\n",
      "Delayed Information, Counterinformation\n",
      "(549, 11)\n",
      "IIO Report Documents Police Contempt for Oversight Agencies\n",
      "(548, 11)\n",
      "Still No Oversight, Still No Accountability\n",
      "(547, 11)\n",
      "A Troubled Explanation\n",
      "(546, 11)\n"
     ]
    }
   ],
   "source": [
    "#Filter out lists in KCC to get just posts about incidents\n",
    "print(KCC.shape)\n",
    "Excluders=['C.R.A.P', \n",
    " 'Police-Involved Deaths in Canada in 2017:',\n",
    " 'People who Died Following a Police Intervention Since 1987',\n",
    " 'Activists Killed by Cops',\n",
    " 'A Victim of Power',\n",
    " 'Third Consecutive Yearly Increase in Police-Involved Deaths in BC',\n",
    " 'Deadly Force',\n",
    " 'Delayed Information, Counterinformation',\n",
    " 'IIO Report Documents Police Contempt for Oversight Agencies',\n",
    " 'Still No Oversight, Still No Accountability', \n",
    " 'A Troubled Explanation']\n",
    "for ex in Excluders:\n",
    "    print(ex)\n",
    "    if ex == 'C.R.A.P':\n",
    "        KCC = KCC.loc[KCC['Text'].str.contains(ex)==False]\n",
    "    else:\n",
    "        KCC = KCC.loc[KCC['Title'].str.contains(ex)==False]\n",
    "    print(KCC.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values\n",
    "* This was my first attempt at filling the gaps, maunually creating a new spreadhseet & adding records\n",
    "* Many of the records were pulled from killercopscanada blog.\n",
    "* Some others were added from other sources\n",
    "    * Where KCC is he linked source, I'll add the text post as the text summary and add it to PID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MD = pd.read_csv('MissingRecords_Skeeter_2021.csv',parse_dates=['Date'],index_col=['id_victim'])\n",
    "MD = MD.fillna('')\n",
    "# Find any records missing a summary and add it from the source\n",
    "# I've already done for most records \n",
    "# print(MD[['summary','KCC_ID']])\n",
    "for i, row in MD.loc[MD['data_source']!='killercopscanada'].iterrows():\n",
    "    if row['summary'] == '':\n",
    "        print(row['Link'])\n",
    "        text = input('Enter Summary')\n",
    "        MD.loc[MD.index==i,'summary']=text\n",
    "\n",
    "# Any KCC posts, add the post text and URL\n",
    "for i,row in MD.loc[MD['data_source']=='killercopscanada'].iterrows():\n",
    "    if row ['summary'] == '':\n",
    "        for l in row['Link'].split(' : '):\n",
    "            if KCC.loc[KCC['URL']==l,'ID'].shape[0]>0:\n",
    "    #             print()\n",
    "                MD.loc[MD.index==i,'KCC_ID']=KCC.loc[KCC['URL']==l,'ID'].values[0]\n",
    "                MD.loc[MD.index==i,'summary']=KCC.loc[KCC['URL']==l,'Text'].values[0]\n",
    "\n",
    "# print(MD['summary'])\n",
    "MD.to_csv('MissingRecords_Skeeter_2021.csv')\n",
    "MD = MD.reset_index().set_index(pd.DatetimeIndex(MD.Date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1472, 35)"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PID = pd.read_csv('CombinedSourceData.csv',parse_dates=['Date'])\n",
    "PID = PID.reset_index(drop=True).set_index(pd.DatetimeIndex(PID.Date))\n",
    "PID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1472\n",
      "Index(['Date', 'id_incident', 'day_week', 'prov', 'city_town',\n",
      "       'address_intersection', 'postal_code', 'location_type', 'first_name',\n",
      "       'middle_name', 'last_name', 'alias_nickname', 'age', 'gender', 'race',\n",
      "       'ethnic_ancestry', 'immigrant_refugee_naturalized', 'armed_type',\n",
      "       'cause_death', 'taser_deployed', 'injured_officer', 'excited_delirium',\n",
      "       'mentral_distress_disorder', 'substance_abuse', 'summary', 'department',\n",
      "       'charge_type', 'charges', 'officers involved', 'name', 'data_source',\n",
      "       'Inquest date', 'GS_match', 'laCRAP_match', 'MD_match',\n",
      "       'DEATH CATEGORY', 'Link', 'KCC_ID'],\n",
      "      dtype='object')\n",
      "(1650, 38)\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any \"same\" names within a 60 day window, allowing for typos.\n",
    "# Check for missing names within a shorter widow, didnt find any tho\n",
    "# Add any other records\n",
    "# PID = PID.copy()\n",
    "Window_named = 60\n",
    "Window_Unnamed = 5\n",
    "SimThresh=.75\n",
    "# c = 0\n",
    "# MD['Append'] = 1\n",
    "MD['MD_match'] = 'None'\n",
    "PID['MD_match'] = 'None'\n",
    "# PID['CBC_id'] \n",
    "print(PID.count()['name'])\n",
    "for i,row in MD.iterrows():\n",
    "    if row['name']!='Unspecified':\n",
    "        Match1=(difflib.get_close_matches(row['name'],PID['name'], cutoff=SimThresh))\n",
    "        Subset = PID.loc[((np.abs(PID.index-i)<datetime.timedelta(Window_named))&\n",
    "                               (PID['name'].isin(Match1))&\n",
    "                               (PID['prov']==row['prov']))]\n",
    "#         if row['name'] == 'Randy Trenholm':\n",
    "#             print(row,Match1)\n",
    "        if Subset.shape[0]>0:\n",
    "            PID.loc[PID['id_victim']==Subset['id_victim'].values[0],'MD_match'] = row['id_victim']\n",
    "            MD.loc[MD['id_victim']==row['id_victim'],'MD_match']=Subset['id_victim'].values[0]\n",
    "\n",
    "PID = PID.append(MD)\n",
    "# print(PID.loc[PID['MD_match']!='None'].shape)\n",
    "# print(PID.loc[PID['MD_match']=='None'].shape)\n",
    "\n",
    "# print(PID.columns)\n",
    "\n",
    "PID = PID.set_index('id_victim')\n",
    "# print(PID.loc[PID['name']=='Randy Trenholm'].index.values)\n",
    "# print(PID.shape)\n",
    "for i,row in PID.loc[((PID['MD_match']!='None'))].iterrows():\n",
    "#     if i == '1251_CRAP' or i == 'MR_9':\n",
    "#     print(i)\n",
    "    Match = PID.loc[PID['MD_match']==i]\n",
    "#     print(Match['prov'].values,row['prov'])\n",
    "    if i.split('_')[-1]=='CRAP':\n",
    "#         print(row)\n",
    "#         print(Match.index)\n",
    "        if Match['prov'].values[0] != row['prov']:\n",
    "            print('?')\n",
    "        else:\n",
    "#             print(PID.shape)\n",
    "#             print(Match,i)\n",
    "            PID=PID.drop(i)\n",
    "#     elif (row['MD_match'].split('_')[-1]!='CRAP') and (i.split('_')[0]=='MD') :\n",
    "#         if \n",
    "    elif i.split('_')[0]!='MR':\n",
    "#         print(row)\n",
    "#         print(Match.index)\n",
    "        PID.loc[(PID.index==i),'summary'] += PID.loc[(PID.index==i),'summary']\n",
    "        PID.loc[(PID.index==i),'KCC_ID'] = PID.loc[(PID.index==i),'KCC_ID']\n",
    "        PID=PID.drop(row['MD_match'])\n",
    "#             print(PID.shape)\n",
    "print(PID.columns)\n",
    "print(PID.shape)\n",
    "# print(PID.loc[PID['name']=='Randy Trenholm'])\n",
    "PID['last_name']=PID['last_name'].fillna('Unspecified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KCC_ID\n",
      "1009_KCC     1\n",
      "1739_KCC     1\n",
      "1732_KCC     1\n",
      "1729_KCC     1\n",
      "1721_KCC     1\n",
      "            ..\n",
      "1279_KCC     2\n",
      "1217_KCC     2\n",
      "1155_KCC     2\n",
      "997_KCC      2\n",
      "993_KCC     33\n",
      "Name: prov, Length: 140, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print(PID.loc[PID.index])\n",
    "PID.loc[PID['KCC_ID']=='None','KCC_ID']=np.nan\n",
    "PID.loc[PID['KCC_ID']=='','KCC_ID']=np.nan\n",
    "print(PID.groupby('KCC_ID').count()['prov'].sort_values())\n",
    "# print(KCC.loc[KCC['ID']=='993_KCC'])\n",
    "\n",
    "PID = PID.reset_index(drop=False).set_index(pd.DatetimeIndex(PID.Date))\n",
    "PID['KCC_ID']=PID['KCC_ID'].fillna('')\n",
    "Exclude = PID.loc[((PID['KCC_ID']!='')),\n",
    "              'KCC_ID'].values\n",
    "# print(Exclude)\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "STOPWORDS.add('man')\n",
    "\n",
    "for i,row in KCC.iterrows():\n",
    "    T=row['Title'].lower()\\\n",
    "    .replace('[{0}]*'.format(string.punctuation), '')\\\n",
    "    .strip()\\\n",
    "    .split()\n",
    "    List =[]\n",
    "    for word in T:\n",
    "        if word not in STOPWORDS:\n",
    "            List.append(word)\n",
    "#         List.append\n",
    "    S = set(List)\n",
    "#     print(S)\n",
    "    KCC.loc[KCC.index==i,'JustWords_Title']=[S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 14)\n",
      "(178, 14)\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "DDDDD\n",
      "\n",
      "Dated -\n",
      "Matched:  211\n",
      "NotDated -\n",
      "Matched:  143\n",
      "Not Matched:  54\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PID['middle_name']=PID['middle_name'].fillna('')\n",
    "KCC['id_victim']=''\n",
    "KCC['Match']=0.0\n",
    "KCC['name']=''\n",
    "Dated = KCC.loc[((KCC['TitleDate'].isnull()==False)&(KCC['ID'].isin(Exclude)==False))].copy()\n",
    "NotDated = KCC.loc[((KCC['TitleDate'].isnull()==True)&(KCC['ID'].isin(Exclude)==False))].copy()\n",
    "# print(KCC.shape)\n",
    "print(Dated.shape)\n",
    "print(NotDated.shape)\n",
    "Named = PID.copy()#loc[PID.name!='Unspecified']\n",
    "\n",
    "# for \n",
    "Window_d = 4\n",
    "Thresh = .85\n",
    "Dated = Dated.reset_index(drop=True).set_index(pd.DatetimeIndex(Dated.TitleDate))\n",
    "# print(Dated.columns)\n",
    "for i,row in Named.iterrows():#.loc[Named['id_victim']=='MR_205']\n",
    "    Match = Dated.loc[np.abs(Dated.index-i)<=datetime.timedelta(Window_d)].copy()\n",
    "    if Match.shape[0]>0 and row['name']!='Unspecified':\n",
    "        \n",
    "        LN=row['last_name'].lower()\n",
    "        Match['match'] = Match.JustWords_Title.apply(lambda words: difflib.get_close_matches(LN,words, cutoff=Thresh))\n",
    "        \n",
    "        if Match.shape[0]>0:#.loc[Match['match'].str.len()!=0]\n",
    "            for j,row2 in Match.loc[Match['match'].str.len()!=0].iterrows():\n",
    "                Named.loc[Named.id_victim==row['id_victim'],'KCC_ID'] += ' ' + row2['ID']\n",
    "                Named.loc[Named.id_victim==row['id_victim'],'summary'] += '       ' + row2['Text']\n",
    "                Dated.loc[Dated['ID']==row2['ID'],'Match']+=1\n",
    "                Dated.loc[Dated['ID']==row2['ID'],'id_victim']+=';'+row['id_victim']\n",
    "                Dated.loc[Dated['ID']==row2['ID'],'name']+=';'+row['name']\n",
    "#         else:\n",
    "            for j,row2 in Match.loc[Match['match'].str.len()==0].iterrows():\n",
    "                if can_province_keys[row['prov']] in row2['Categories']:\n",
    "                    Named.loc[Named.id_victim==row['id_victim'],'KCC_ID'] += ' ***' + row2['ID']\n",
    "                    Named.loc[Named.id_victim==row['id_victim'],'summary'] += '       ***' + row2['Text']\n",
    "                    Dated.loc[Dated['ID']==row2['ID'],'Match']+=.0001\n",
    "                    Dated.loc[Dated['ID']==row2['ID'],'id_victim']+=';**'+row['id_victim']\n",
    "                    Dated.loc[Dated['ID']==row2['ID'],'name']+=';**'+row['name']\n",
    "\n",
    "    elif Match.shape[0]>0:\n",
    "        for j,row2 in Match.iterrows():\n",
    "            if can_province_keys[row['prov']] in row2['Categories']:\n",
    "                Named.loc[Named.id_victim==row['id_victim'],'KCC_ID'] += ' **' + row2['ID']\n",
    "                Named.loc[Named.id_victim==row['id_victim'],'summary'] += '       **' + row2['Text']\n",
    "                Dated.loc[Dated['ID']==row2['ID'],'Match']+=.01\n",
    "                Dated.loc[Dated['ID']==row2['ID'],'id_victim']+=';**'+row['id_victim']\n",
    "                Dated.loc[Dated['ID']==row2['ID'],'name']+=';**'+row['name']\n",
    "                \n",
    "c = 0\n",
    "NotDated = NotDated.append(Dated.loc[Dated['Match']==0])\n",
    "for i,row in Named.loc[Named['name']!='Unspecified'].iterrows():\n",
    "    LN=row['last_name'].lower()\n",
    "#         Dated['match'] = Dated.JustWords_Title.apply(lambda words: difflib.get_close_matches(LN,words, cutoff=Thresh))\n",
    "    NotDated['match'] = NotDated.JustWords_Title.apply(lambda words: difflib.get_close_matches(LN,words, cutoff=Thresh))\n",
    "#         print(NotDated['match'].sum())  \n",
    "    for j,row2 in NotDated.loc[NotDated['match'].str.len()!=0].iterrows():\n",
    "        if can_province_keys[row['prov']] in row2['Categories'] or row['prov'] == row2['prov']:\n",
    "            print('DDDDD')\n",
    "            Named.loc[Named.id_victim==row['id_victim'],'KCC_ID'] += ' *' + row2['ID']\n",
    "            Named.loc[Named.id_victim==row['id_victim'],'summary'] += '       *' + row2['Text']\n",
    "            NotDated.loc[NotDated['ID']==row2['ID'],'Match']+=.1\n",
    "            NotDated.loc[NotDated['ID']==row2['ID'],'id_victim']+=';**'+row['id_victim']\n",
    "            NotDated.loc[NotDated['ID']==row2['ID'],'name']+=';**'+row['name']\n",
    "#         else:\n",
    "#             print(c)\n",
    "#             c+=1\n",
    "#             print(row['name'])\n",
    "#             print(row2['Title'])\n",
    "#             print(row2['Categories'])\n",
    "print()\n",
    "print('Dated -')\n",
    "# print('Not Matched: ',Dated.loc[Dated['Match']==0].shape[0])\n",
    "print('Matched: ',Dated.loc[Dated['Match']>0].shape[0])\n",
    "print('NotDated -')\n",
    "print('Matched: ',NotDated.loc[NotDated['Match']>0].shape[0])\n",
    "print('Not Matched: ',NotDated.loc[NotDated['Match']==0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    197.000000\n",
      "mean       0.108629\n",
      "std        0.102403\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.100000\n",
      "75%        0.100000\n",
      "max        0.500000\n",
      "Name: Match, dtype: float64\n",
      "Date\n",
      "2018-11-27    Jorden Joseph McKay\n",
      "2008-06-14            Chase McKay\n",
      "2017-07-19     Marlon Jerry McKay\n",
      "Name: name, dtype: object\n",
      "2018-11-29 23:53:52    Cops Investigating Cops: OPP Investigate RNC i...\n",
      "2017-07-22 07:13:45    Victim of Thunder Bay Police Identified as Mar...\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(NotDated['Match'].describe())\n",
    "\n",
    "print(PID.loc[PID['last_name']=='McKay','name'])\n",
    "\n",
    "NotDated['match'] = NotDated.JustWords_Title.apply(lambda words: difflib.get_close_matches('mckay',words, cutoff=Thresh))\n",
    "print(NotDated.loc[NotDated['match'].str.len()==1,'Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2015-04-05    Royal Newfoundland Constabulary\n",
      "2000-08-26                               RCMP\n",
      "2000-10-16    Royal Newfoundland Constabulary\n",
      "2018-11-27    Royal Newfoundland Constabulary\n",
      "1996-03-02                            Unknown\n",
      "2018-04-13                            Unknown\n",
      "Name: department, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(PID.loc[PID.prov=='NL','department'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "# print(KCC['JustWords_Title'][0])\n",
    "\n",
    "# KCC['JustWords_Text'] = [set(words) for words in\n",
    "#     KCC['Text']\n",
    "#     .str.lower()\n",
    "#     .str.replace('[{0}]*'.format(string.punctuation), '')\n",
    "#     .str.strip()\n",
    "#     .str.split()\n",
    "# ]\n",
    "print(KCC['JustWords_Title'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Matching records in KCC\n",
    "* This is the next step, match up existing recrods.  Append missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "PID['middle_name']=PID['middle_name'].fillna('Unspecified')\n",
    "KCC['Match']=0\n",
    "KCC['id_victim']=''\n",
    "KCC['name']=''\n",
    "KCC['Exclude'] = False\n",
    "for ex in Exclude:\n",
    "    KCC.loc[KCC.ID==ex,'Exclude']=True\n",
    "    KCC.loc[KCC.ID==ex,'Match']+=1\n",
    "    KCC.loc[KCC.ID==ex,'id_victim']=PID.loc[PID.KCC_ID==ex,'id_victim'].values[0]\n",
    "    KCC.loc[KCC.ID==ex,'name']=PID.loc[PID.KCC_ID==ex,'name'].values[0]\n",
    "# KCC_BU = KCC.copy()\n",
    "KCC_EX = KCC.loc[KCC['Exclude']==True]\n",
    "KCC = KCC.loc[KCC['Exclude']==False]\n",
    "\n",
    "print(KCC.shape)\n",
    "print(KCC_EX.shape)\n",
    "LThresh=.85\n",
    "FMThresh=.7\n",
    "# SimThresh=.75\n",
    "# PID['KCC']\n",
    "for i,row in PID.loc[((PID.name!='Unspecified'))].iterrows():\n",
    "#     print(row['id_victim'])\n",
    "    LN=row['last_name'].lower()#.copy()\n",
    "    FN=row['first_name'].lower()#.copy()\n",
    "    MN=row['middle_name'].lower()#.copy()\n",
    "    if len(MN)<=2:\n",
    "        MN = 'Unspecified'\n",
    "#     print(len(MN),'   ',MN)\n",
    "    KCC['matchL'] = KCC.JustWords_Title.apply(lambda words: difflib.get_close_matches(LN,words, cutoff=LThresh))\n",
    "    KCC['matchF'] = KCC.JustWords_Title.apply(lambda words: difflib.get_close_matches(FN,words, cutoff=FMThresh))\n",
    "    KCC['matchM'] = KCC.JustWords_Title.apply(lambda words: difflib.get_close_matches(MN,words, cutoff=FMThresh))\n",
    "    if KCC.loc[(((KCC['matchL'].str.len()!=0)&(KCC['matchF'].str.len()!=0))|\n",
    "               ((KCC['matchL'].str.len()!=0)&(KCC['matchM'].str.len()!=0)))].shape[0]>0:\n",
    "#         print(row['name'])\n",
    "#         print(KCC.loc[((KCC['matchL'].str.len()!=0)&(KCC['matchF'].str.len()!=0)),'Title'].values)\n",
    "        for j,row2 in KCC.loc[(((KCC['matchL'].str.len()!=0)&(KCC['matchF'].str.len()!=0))|\n",
    "               ((KCC['matchL'].str.len()!=0)&(KCC['matchM'].str.len()!=0)))].iterrows():\n",
    "            PID.loc[PID.id_victim==row['id_victim'],'KCC_ID'] += ' ' + row2['ID']\n",
    "            PID.loc[PID.id_victim==row['id_victim'],'summary'] += '       ' + row2['Text']\n",
    "        KCC.loc[(((KCC['matchL'].str.len()!=0)&(KCC['matchF'].str.len()!=0))|\n",
    "               ((KCC['matchL'].str.len()!=0)&(KCC['matchM'].str.len()!=0))),'Match']+=1\n",
    "        KCC.loc[(((KCC['matchL'].str.len()!=0)&(KCC['matchF'].str.len()!=0))|\n",
    "               ((KCC['matchL'].str.len()!=0)&(KCC['matchM'].str.len()!=0))),'id_victim']+=';'+row['id_victim']\n",
    "        KCC.loc[(((KCC['matchL'].str.len()!=0)&(KCC['matchF'].str.len()!=0))|\n",
    "               ((KCC['matchL'].str.len()!=0)&(KCC['matchM'].str.len()!=0))),'name']+=';'+row['name']\n",
    "        \n",
    "\n",
    "KCC = KCC.append(KCC_EX)\n",
    "print(KCC.loc[KCC['Match']==0].shape)\n",
    "print(KCC.loc[KCC['Match']>0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(KCC.loc[KCC['Match']==0,['Title','TitleDate']].count())\n",
    "print(KCC.loc[KCC['Match']>=2,['Title','name','prov']][0:20].values)\n",
    "# print(KCC.loc)\n",
    "print(PID.loc[PID['last_name']=='Campbell',['first_name','middle_name','KCC_ID','prov']])\n",
    "\n",
    "# print(KCC.loc[KCC['Title'].str.contains('Killing of Dudley George')==True,['Title','Match']].values)\n",
    "\n",
    "# Window_d=3\n",
    "\n",
    "print(KCC.JustWords_Title.apply(lambda words: difflib.get_close_matches('Jason',words, cutoff=.7)).sum())\n",
    "# KCC['matchF'] = KCC.JustWords_Title.apply(lambda words: difflib.get_close_matches('Dudley',words, cutoff=FMThresh))\n",
    "# print(KCC.loc[(((KCC['matchL'].str.len()!=0)&(KCC['matchF'].str.len()!=0))|\n",
    "#                ((KCC['matchL'].str.len()!=0)&(KCC['matchM'].str.len()!=0)))])\n",
    "# KCC.loc[((KCC['matchL'].str.len()!=0)&(KCC['matchF'].str.len()!=0))]\n",
    "# print(PID.loc[PID['KCC_ID'].str.contains('415_KCC')])\n",
    "# print(KCC.loc[KCC['ID']=='415_KCC'])\n",
    "# for i,row in KCC.loc[((KCC['Match']==0)&(KCC['TitleDate'].isnull()==True))].iterrows():\n",
    "#     print(row['TitleDate'],row['prov'])\n",
    "#     Match = PID.loc[((np.abs(PID.index-row['TitleDate'])<=datetime.timedelta(Window_d))&(PID['prov'] == row['prov']))]\n",
    "#     print(Match.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KCC['JustWords_Title'] = [set(words) for words in\n",
    "#     KCC['Title']\n",
    "#     .str.lower()\n",
    "#     .str.replace('[{0}]*'.format(string.punctuation), '')\n",
    "#     .str.strip()\n",
    "#     .str.split()\n",
    "# ]\n",
    "\n",
    "# KCC['JustWords_Text'] = [set(words) for words in\n",
    "#     KCC['Text']\n",
    "#     .str.lower()\n",
    "#     .str.replace('[{0}]*'.format(string.punctuation), '')\n",
    "#     .str.strip()\n",
    "#     .str.split()\n",
    "# ]\n",
    "# PID['middle_name']=PID['middle_name'].fillna('')\n",
    "# for i,row in PID.loc[((PID.index.year>=2014)&(PID.KCC_ID!='Unspecified')&(PID.name!='Unspecified'))].iterrows():\n",
    "# #     print(i)\n",
    "#     target_words=[row['last_name']]\n",
    "#     target_words = [word.lower() for word in target_words]\n",
    "#     KCC['matchL'] = KCC.JustWords_Title.apply(lambda words: all(target_word in words \n",
    "#                                            for target_word in target_words))\n",
    "#     if KCC['matchL'].sum()>0:\n",
    "#         Set = KCC.loc[KCC['matchL']==True].copy()\n",
    "#         target_words=[row['first_name'],row['middle_name']]\n",
    "# #         print(target_words)\n",
    "#         target_words = [word.lower() for word in target_words]\n",
    "#         Set['matchFM'] = Set.JustWords_Title.apply(lambda words: any (target_word in words \n",
    "#                                                for target_word in target_words))\n",
    "# #         Set['match'] = Set['matchL']+Set['matchFM']\n",
    "# #         print(Set['match'].sum())\n",
    "#         if Set['matchFM'].sum()>0:\n",
    "#             print(Set['Title'],row['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# KCC['id_victim'] = ''\n",
    "# KCC['Title_Match'] = 0\n",
    "# KCC['Text_Match'] = 0\n",
    "# KCC['Names']=''\n",
    "# PID['Matches'] = 0# \n",
    "# # print(PID['Matches'])\n",
    "\n",
    "# Title_Match = {}\n",
    "# Text_Match = {}\n",
    "# # print(PID['Matches'])\n",
    "# R = 1\n",
    "# PID['KCC_ID']=PID['KCC_ID'].fillna('')\n",
    "# for i, row in PID.iterrows():\n",
    "#     Title_Match[i]=[]\n",
    "#     if row['KCC_ID']!='Unspecified':\n",
    "#         KCC.loc[KCC['ID'] == row['KCC_ID'],'Match'] += 1\n",
    "#     if 'Unspecified' not in row['name']:\n",
    "#         target_words = [row['first_name'], row['last_name']]\n",
    "# #         print()\n",
    "# #         print(i,row['name'])\n",
    "# #         print(target_words)\n",
    "#         target_words = [word.lower() for word in target_words]\n",
    "# #         if i=='264_CRAP':\n",
    "# #             print(target_words)\n",
    "#         KCC['match'] = KCC.JustWords_Title.apply(lambda words: all(target_word in words \n",
    "#                                                for target_word in target_words))\n",
    "        \n",
    "#         KCC.loc[KCC['match']==True,'Title_Match']+=1\n",
    "# #         KCC_ID = row['KCC_ID']\n",
    "#         KCC.loc[KCC['match']==True,'id_victim'] += i+' '\n",
    "#         KCC.loc[KCC['match']==True,'Names']+=row['name']+' ; '\n",
    "#         if KCC['match'].sum()>0:\n",
    "#             for i2,row2 in KCC.loc[KCC['match']].iterrows():\n",
    "#                 if row2['ID'] not in row['KCC_ID']:\n",
    "#                     PID.loc[PID.index==i,'KCC_ID']+= ' '+row2['ID']\n",
    "#                     PID.loc[PID.index==i,'summary']+= '    '+row2['Title']+'    '+row2['Text']\n",
    "# #                     print(row['KCC_ID'],row2['ID'])\n",
    "#         else:\n",
    "#             target_words = [row['last_name']]\n",
    "# #             print(target_words)\n",
    "#             target_words = [word.lower() for word in target_words]\n",
    "#             KCC['match'] = KCC.JustWords_Title.apply(lambda words: all(target_word in words \n",
    "#                                                    for target_word in target_words))\n",
    "#             KCC.loc[((KCC['match']==True)&(KCC['Title_Match']==0)),'Text_Match']+=1\n",
    "# #             KCC_ID = row['KCC_ID']\n",
    "#             KCC.loc[((KCC['match']==True)&(KCC['Title_Match']==0)),'id_victim'] += i+' '\n",
    "#             KCC.loc[((KCC['match']==True)&(KCC['Title_Match']==0)),'Names']+=row['name']+' ; '\n",
    "#             if KCC['match'].sum()>0:\n",
    "#                 for i2,row2 in KCC.loc[((KCC['match']==True)&(KCC['Title_Match']==0))].iterrows():\n",
    "#                     if row2['ID'] not in row['KCC_ID']:\n",
    "#                         PID.loc[PID.index==i,'KCC_ID']+= ' '+row2['ID']\n",
    "#                         PID.loc[PID.index==i,'summary']+= '    '+row2['Title']+'    '+row2['Text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(PID.loc[PID.index=='83_GS',['first_name','middle_name','last_name']])\n",
    "# print(PID.loc[PID['KCC_ID']== ''].shape)\n",
    "KCC['Matches'] = KCC[['Title_Match','Text_Match']].sum(axis=1)\n",
    "\n",
    "# print(KCC['Matches'].sort_values())\n",
    "print(KCC.loc[KCC['Matches']==0].shape)\n",
    "print(KCC.loc[KCC['Matches']>=1].shape)\n",
    "# print(KCC.loc[KCC['Text'].str.contains('C.R.A.P')].shape)\n",
    "# \n",
    "\n",
    "Exclude = PID.loc[((PID['KCC_ID']!='')),\n",
    "              'KCC_ID'].values\n",
    "print(Exclude.shape)\n",
    "EX = []\n",
    "for V in Exclude:\n",
    "    for v in V.split(' '):\n",
    "        if v !='' and v not in EX:\n",
    "            EX.append(v)\n",
    "    \n",
    "print(len(EX))\n",
    "\n",
    "Dated = KCC.loc[((KCC['TitleDate'].isnull()==False)&(KCC['ID'].isin(EX)==False))]\n",
    "NotDated = KCC.loc[((KCC['TitleDate'].isnull()==True)&(KCC['ID'].isin(EX)==False))]\n",
    "\n",
    "print(Dated.loc[Dated['Match']==0,'Title'].shape)\n",
    "print(NotDated.loc[NotDated['Match']==0,'Title'].shape)\n",
    "print(NotDated.loc[NotDated['Match']==0,'Title'].values)\n",
    "\n",
    "print(KCC.loc[KCC['Title']=='A Troubled Explanation: Using Victims’ Histories of Mental Illness to Excuse Killer Cops','Text'].values)\n",
    "# Excluders.append('A Troubled Explanation: Using Victims’ Histories of Mental Illness to Excuse Killer Cops')\n",
    "# print(Excluders)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(KCC.loc[KCC['Title']=='A Troubled Explanation: Using Victims’ Histories of Mental Illness to Excuse Killer Cops','Text'].values)\n",
    "# Excluders.append('A Troubled Explanation: Using Victims’ Histories of Mental Illness to Excuse Killer Cops')\n",
    "# print(Excluders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "Window_d=2\n",
    "c = 0\n",
    "# # print(KCC.loc[KCC['Match']==0,'ID'].count())\n",
    "for i,row in Dated.iterrows():\n",
    "    Match = PID.loc[((np.abs(PID.index-row['TitleDate'])<=datetime.timedelta(Window_d))&(PID['prov'] == row['prov']))]\n",
    "    if Match['id_victim'].count()>=1:\n",
    "        c +=1\n",
    "        for v in Match['id_victim']:\n",
    "#     #         print('/')\n",
    "            print('Post')\n",
    "            print(row[['ID','Matches']])\n",
    "            print(row['Title'])\n",
    "            print(row['Text'])\n",
    "            print()\n",
    "            print('Record')\n",
    "#             print(Match['id_victim'].count(),Match['Matches'].sum())\n",
    "            print(PID.loc[PID['id_victim']==v,'summary'].values)\n",
    "            print(PID.loc[PID['id_victim']==v,['id_victim','name','age','department','city_town','gender','KCC_ID']])\n",
    "#             print(Match['KCC_ID'])\n",
    "        \n",
    "        \n",
    "            Match = input('Match: y/n')\n",
    "            if Match == 'y':\n",
    "                PID.loc[PID['id_victim']==v,'summary'] += '      '+ row['Text']\n",
    "                PID.loc[PID['id_victim']==v,'KCC_ID'] += row['ID']+' '\n",
    "                KCC.loc[KCC['ID']==row['ID'],'Matches']+=1\n",
    "                KCC.loc[KCC['ID']==row['ID'],'id_victim']+=v+' '\n",
    "#             print()\n",
    "            clear_output()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = (PID.loc[PID.id_victim=='264_CRAP',['first_name','last_name']])\n",
    "\n",
    "# target_words = [row['first_name'][0].lower(), row['last_name'][0].lower()]\n",
    "# print(target_words)\n",
    "# print(KCC.loc[KCC.ID=='1735_KCC','JustWords_Title'].values)\n",
    "# # print(KCC.loc[KCC['ID']=='993_KCC','Tags'].values)\n",
    "# KCC.JustWords_Title.apply(lambda words: all(target_word in words \n",
    "#                                                for target_word in target_words)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(PID.columns)\n",
    "\n",
    "PID['Check']=True\n",
    "PID.loc[(PID['postal_code']!='Unspecified'),'Check']=False\n",
    "Summary = PID[['summary','data_source']]\n",
    "Summary['extra_source'] = ''\n",
    "Summary.to_csv('Compiled/Summary.csv')\n",
    "Location = PID[['prov', 'city_town','address_intersection', 'postal_code','Check']]\n",
    "Location.to_csv('Compiled/Location.csv')\n",
    "Victim = PID[['name','first_name', 'middle_name', 'last_name', 'alias_nickname', 'age',\n",
    "       'gender', 'race', 'ethnic_ancestry']]\n",
    "Victim.to_csv('Compiled/Victim.csv')\n",
    "Incident = PID[['Date','armed_type', 'cause_death','DEATH CATEGORY', 'taser_deployed', 'injured_officer',\n",
    "       'excited_delirium', 'mentral_distress_disorder', 'substance_abuse','department',\n",
    "        'charge_type', 'charges', 'officers involved','data_source', 'Inquest date']]\n",
    "\n",
    "Incident.to_csv('Compiled/Incident.csv')\n",
    "# print(Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PID.loc[PID['KCC_ID']=='Unspecified','prov'].count())\n",
    "print(PID.loc[PID['KCC_ID']!='Unspecified','prov'].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PID['Check']=True\n",
    "PID.loc[(PID['postal_code']!='Unspecified'),'Check']=False\n",
    "\n",
    "PID.index=PID.index.rename('Date')\n",
    "PID.to_csv('Combined_Data.csv')\n",
    "print(PID.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
